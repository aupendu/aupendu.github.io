<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no" />

    <!--Update this for shortest possible description-->
    <meta name="description"
        content="Sub-Aperture Feature Adaptation in Single Image Super-resolution Model for Light Field Imaging." />

    <!--This part is to give credit to the person who developed the site-->
    <meta name="author" content="Aniket Patra" />

    <!---------------------og tags are for open graph ----------------->
    <meta property="og:title" content="LFSAFA-SR" />

    <meta property="og:url" content="https://aupendu.github.io/LFSAFA-SR" />
    <meta property="og:image" content="https://aupendu.github.io/assets/images/lfsafa_thumb.jpg" />
    <meta property="og:image:type" content="image/jpg" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />
    <meta property="og:image:alt" content="Iterative Dehazing Training Stage 3" />

    <meta property="og:type" content="article" />
    <meta property="og:description"
        content="Sub-Aperture Feature Adaptation in Single Image Super-resolution Model for Light Field Imaging." />

    <meta property="og:locale" content="en_IN" />
    <meta property="og:locale:alternate" content="en_US" />

    <!---------------TWITTER CRDS------------------------>
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="LFSAFA-SR" />
    <meta name="twitter:description"
        content="Sub-Aperture Feature Adaptation in Single Image Super-resolution Model for Light Field Imaging." />
    <meta name="twitter:url" content="https://aupendu.github.io/LFSAFA-SR" />
    <meta name="twitter:image" content="https://aupendu.github.io/assets/images/lfsafa_thumb.jpg" />

    <title>LFSAFA-SR</title>

    <!--Page Icon-->
    <link rel="icon" type="image/png" href="assets/images/ak2.ico" />

    <!--STYLESHEETS (.css)-->

    <!--For Bootstrap 5-->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

    <!--Extrenal css-->
    <link rel="stylesheet" href="lfsafa-sr/subpage.css" />
</head>

<body>
    <div class="container" style="background-color: rgb(255, 255, 255)">
        <!--Top Nav-->
        <header>
            <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
                <div class="container-fluid">
                    <a class="navbar-brand" href="https://aupendu.github.io/"><i
                            class="fas fa-house-user d-inline-block"></i></a>
                    <button class="navbar-toggler" type="button" data-bs-toggle="collapse"
                        data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
                        aria-expanded="false" aria-label="Toggle navigation">
                        <span class="navbar-toggler-icon"></span>
                    </button>
                    <div class="collapse navbar-collapse" id="navbarSupportedContent">
                        <ul class="navbar-nav me-auto mb-2 mb-lg-0">
                            <li class="nav-item">
                                <a class="nav-link" href="#sectionResult">Result</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" href="#download">Download</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" href="#cite">Citation</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" id="mailTo">Contact</a>
                            </li>
                        </ul>
                    </div>
                </div>
            </nav>
        </header>

        <!--Topic Name-->
        <h1 style="
          text-align: center;
          font-size: calc(25px + 0.5vw);
          font-family: 'Raleway', sans-serif;
          font-weight: bold;
        ">
            Sub-Aperture Feature Adaptation in Single Image Super-resolution Model for Light Field Imaging
        </h1>

        <!--Author Name-->

        <h2 style="
          text-align: center;
          font-size: calc(10px + 0.5vw);
          font-family: 'Roboto', sans-serif;
        ">
            <a href="https://github.com/aupendu" target="_blank" style="text-decoration: none; color: rgb(70, 70, 70)"
                onmouseover="this.style.color='gray'" onmouseout="this.style.color='rgb(70, 70, 70)'"><u>Aupendu
                    Kar</u></a>, Suresh Nehra, Jayanta Mukhopadhyay, Prabir Kumar Biswas
        </h2>

        <!--Institution Name-->

        <h3 style="
          text-align: center;
          font-size: calc(10px + 0.5vw);
          font-family: 'Roboto', sans-serif;
        ">
            Department of Electronics and Electrical Communication Engineering
            <br />
            Indian Institute of Technology Kharagpur, India
        </h3>
        <hr />
        <!-------------------------------FIGURE 1--------------------------->
        <div class="row ">
            <div class="col d-flex justify-content-center">
                <figure class="figure">
                    <span class="d-flex justify-content-center">
                        <img class="img-fluid figure-img" src="assets/lfsafa-sr/teaser/fig1.jpg"
                            class="figure-img img-fluid rounded" title="Image Training" height="600" width="600"
                            alt="machine learning image training diagram" /></a></span>
                    <figcaption class="text-center" id="figCap">
                        Feature extraction and upscale module are from any
                        pre-trained SISR model. The adaptation module aims to learn
                        more information from multiple sub-aperture images. During
                        training, the weights of the adaptation module are updated
                        (shown as an 'unlocked' symbol), and the weights of two pre-
                        trained modules are fixed (shown using 'locked' symbols)
                        <!--EDIT CAPTION HERE-->
                    </figcaption>
                </figure>
            </div>
        </div>
        <hr>
        <!------------------------------ABSTRACT-------------------->
        <h2 id="headingStyles" class="text-center text-md-start">
            <i class="fas fa-lightbulb"></i>&nbsp;Abstract
        </h2>
        <div class="row">
            <div class="col-sm">
                <p style="text-align: justify">
                    With the availability of commercial Light Field (LF) cam-
                    eras, LF imaging has emerged as an up-and-coming tech-
                    nology in computational photography. However, the spatial
                    resolution is significantly constrained in commercial micro-
                    lens-based LF cameras because of the inherent multiplexing
                    of spatial and angular information. Therefore, it becomes the
                    main bottleneck for other applications of light field cameras.
                    This paper proposes an adaptation module in a pre-trained
                    Single Image Super-Resolution (SISR) network to leverage
                    the powerful SISR model instead of using highly engineered
                    light field imaging domain-specific Super Resolution models.
                    The adaption module consists of a Sub-aperture Shift block
                    and a fusion block. It is an adaptation in the SISR network
                    to further exploit the spatial and angular information in LF
                    images to improve the super-resolution performance. Exper-
                    imental validation shows that the proposed method outper-
                    forms existing light field super-resolution algorithms. It also
                    achieves PSNR gains of more than 1 dB across all the datasets
                    as compared to the same pre-trained SISR models for scale
                    factor 2, and PSNR gains 0.6 − 1 dB for scale factor 4.
                </p>
            </div>
        </div>
        <hr>
        <!------------------------------HIGHLIGHTS-------------------->
        <h2 id="headingStyles" class="text-center text-md-start">
            <i class="fas fa-satellite-dish"></i>&nbsp;Highlights
        </h2>
        <div class="row" id="jumbo">
            <div class="col">
                <ol type="i">
                    <li>
                        We propose a light-field domain adaptation module to
                        achieve LFSR using SISR models. To the best of our
                        knowledge, this is the first work in this direction.
                    </li>
                    <li>
                        We show that the proposed module can utilize angular
                        information present in SA images to improve the per-
                        formance, and ablation studies support our claims.
                    </li>
                    <li>
                        Our qualitative and quantitative analysis shows that the
                        performance of our method is better than light-field
                        domain-specific super-resolution solutions, and any
                        SISR models can adopt our proposed modification to
                        make it work for LFSR.
                    </li>
                </ol>
            </div>
        </div>
        <hr />
        <!------------------------------Proposed module-------------------->
        <h2 id="headingStyles" class="text-center text-md-start">
            <i class="fas fa-puzzle-piece"></i>&nbsp;Proposed Module
        </h2>
        <div class="row ">
            <!-------------------------------FIGURE 2--------------------------->
            <div class="col d-flex justify-content-center">
                <figure class="figure">
                    <span class="d-flex justify-content-center">
                        <img class="img-fluid figure-img" src="assets/lfsafa-sr/teaser/fig2.jpg"
                            class="figure-img img-fluid rounded" title="Proposed sub-aperture feature adaptation module"
                            height="600" width="600"
                            alt="proposed sub-aperture feature adaptation module image" /></a></span>
                    <figcaption class="text-center" id="figCap">
                        The proposed sub-aperture feature adaptation module
                        consists of <i>n</i> SAS modules and 1 fusion module. <i>f</i><sub>i</sub> is the
                        extracted feature of a sub-aperture image using a pre-trained
                        model <i>F</i><sub>feat</sub> and <i>f'</i><sub>i</sub> is the modulated feature that contains
                        more rich features that are acquired from other sub-aperture
                        images. '<i>Conv, a, b, k</i>' represents 2D convolution with <i>a</i>
                        number of input channels, <i>b</i> number of output channels, and
                        <i>k</i> is the kernel size.
                        ule <i>F</i><sub>feat</sub>, and another one is upscaling cum reconstruction
                        module <i>F</i><sub>up</sub>. <i>F</i><sub>feat</sub> extracts the salient features from a
                        single
                        image that is up-scaled by <i>F</i><sub>up</sub>. Our main objective is to in-
                        troduce a module that modulates the extracted features from
                        <i>F</i><sub>feat</sub> by exploiting angular information across SAIs.
                        <!--EDIT CAPTION HERE-->
                    </figcaption>
                </figure>
            </div>
        </div>
        <hr>
        <!------------------------------Results and ABalation Studies-------------------->
        <div class="row" id="sectionResult">
            <!-------------------------------FIGURE 2--------------------------->
            <div class="col-sm-6">
                <h2 id="headingStyles" class="text-center text-md-start">
                    <i class="fas fa-poll"></i>&nbsp;Results
                </h2>
                <figure class="figure">
                    <span class="d-flex justify-content-center">
                        <img class="img-fluid figure-img" src="assets/lfsafa-sr/resultAbalation/tab1.jpg"
                            class="figure-img img-fluid rounded" title="Proposed sub-aperture feature adaptation module"
                            height="600" width="600"
                            alt="proposed sub-aperture feature adaptation module image" /></a></span>
                    <figcaption class="text-center" id="figCap">
                        Table 1: PSNR/SSIM values achieved by different methods
                        for 2x and 4xSR. Our results are shown in bold
                        <!--EDIT CAPTION HERE-->
                    </figcaption>
                </figure>
            </div>

            <div class="col-sm-6">
                <h2 id="headingStyles" class="text-center text-md-start">
                    <i class="fas fa-poll"></i>&nbsp;Ablation Study
                </h2>
                <div class="row">
                    <div class="col-12">
                        <figure class="figure">
                            <span class="d-flex justify-content-center">
                                <img class="img-fluid figure-img" src="assets/lfsafa-sr/resultAbalation/tab2.jpg"
                                    class="figure-img img-fluid rounded" title="Model ablation studies" height="600"
                                    width="600" alt="Table number 2, caption is mentioned below." /></a></span>
                            <figcaption class="text-center" id="figCap">
                                Table 2: Model ablation studies of our proposed LFSAFA
                                module and the effect of angular resolution on the reconstruction performance. All the
                                experiments are performed on the
                                LFSAFA-RDN variant for 2x SR.
                                <!--EDIT CAPTION HERE-->
                            </figcaption>
                        </figure>
                    </div>
                    <br>
                    <div class="col-12">
                        <figure class="figure">
                            <span class="d-flex justify-content-center">
                                <img class="img-fluid figure-img" src="assets/lfsafa-sr/resultAbalation/tab3.jpg"
                                    class="figure-img img-fluid rounded" title="Comparative analysis" height="600"
                                    width="600" alt="Table number 3, caption is mentioned below." /></a></span>
                            <figcaption class="text-center" id="figCap">
                                Table 3: Comparative analysis of our proposed LFSAFA
                                module-based LFSR models with their SISR counterparts.
                                <!--EDIT CAPTION HERE-->
                            </figcaption>
                        </figure>
                    </div>
                </div>
            </div>
        </div>
        <hr>
        <!------------------------------Visual Comparison-------------------->
        <h2 id="headingStyles" class="text-center text-md-start">
            <i class="fas fa-eye"></i>&nbsp;Visual Comparison
        </h2>
        <div class="row ">
            <!-------------------------------FIGURE 2--------------------------->
            <div class="col d-flex justify-content-center">
                <figure class="figure">
                    <span class="d-flex justify-content-center">
                        <img class="img-fluid figure-img" src="assets/lfsafa-sr/visComparison/fig3.jpg"
                            class="figure-img img-fluid rounded"
                            title="Qualitative comparison of our proposed LFSAFA-RDN" width="1300"
                            alt="Image for qualitative comparison of our proposed LFSAFA-RDN" /></a></span>
                    <figcaption class="text-center" id="figCap">
                        Qualitative comparison of our proposed LFSAFA-RDN with the existing LFSR algorithms for 4x SR
                        <!--EDIT CAPTION HERE-->
                    </figcaption>
                </figure>
            </div>
        </div>
        <hr>
        <!-----------------------DOWNLOADS------------------------------->
        <h2 id="download" class="text-center text-md-start">
            <i class="fas fa-download"></i>&nbsp;Download
        </h2>
        <div class="row">
            <div class="col-sm-4 text-center">
                <figure class="figure">
                    <a href="https://arxiv.org/abs/2207.11894" rel="external nofollow" target="_blank"
                        onmouseover="this.style.opacity='0.5'" onmouseout="this.style.opacity='1'"><img
                            src="assets/images/arxiv.png" alt="Arxiv image icon" width="220px" height="120px"
                            title="Click to Open" />
                    </a>
                    <figcaption class="text-center figure-caption" style="font-size: calc(12px + 0.5vw)">
                        Paper
                    </figcaption>
                </figure>
            </div>
            <div class="col-sm-4 text-center">
                <figure class="figure">
                    <a href="https://github.com/aupendu/LFSAFA-SR" rel="external nofollow" target="_blank"
                        onmouseover="this.style.opacity='0.5'" onmouseout="this.style.opacity='1'"><i
                            class="fab fa-github" style="font-size: 120px; color: rgb(54, 54, 54)"></i>
                    </a>
                    <figcaption class="text-center figure-caption" style="font-size: calc(12px + 0.5vw)">
                        Code
                    </figcaption>
                </figure>
            </div>
            <div class="col-sm-4 text-center">
                <figure class="figure">
                    <a href="#########ENTER_LINK###########" rel="external nofollow" target="_blank"
                        onmouseover="this.style.opacity='0.5'" onmouseout="this.style.opacity='1'"><img
                            src="assets/images/gdrive.png" alt="Google drive image icon" width="150px" height="120px"
                            title="Click to Open" />
                    </a>
                    <figcaption class="text-center figure-caption" style="font-size: calc(12px + 0.5vw)">
                        Training & Testing Datasets
                    </figcaption>
                </figure>
            </div>
        </div>
        <hr />
        <!-------------------------REFERENCES---------------------------->
        <h2 id="headingStyles" class="text-center text-md-start">
            <i class="fas fa-asterisk"></i>&nbsp;References
        </h2>
        <div class="row">
            <div class="col">
                <ul>
                    <li style="text-align: justify">
                        [7] Jiwon Kim, Jung Kwon Lee, and Kyoung Mu Lee, “Accurate image super-resolution using very deep convolutional networks,” in CVPR, 2016, pp. 1646–1654.
                    </li>
                    <li style="text-align: justify">
                        [10] Yulun Zhang, Kunpeng Li, et al., “Image superresolution using very deep residual channel attention networks,” in ECCV, 2018, pp. 286–301
                    </li>
                    <li style="text-align: justify">
                        [11] Shuo Zhang, Youfang Lin, and Hao Sheng, “Residual networks for light field image super-resolution,” in CVPR, 2019, pp. 11046–11055.
                    </li>
                    <li style="text-align: justify">
                        [12] Henry Wing Fung Yeung, et al., “Light field spatial super-resolution using deep efficient spatialangular separable convolution,” IEEE TIP, vol. 28, no. 5, pp. 2319–2330, 2018.
                    </li>
                    <li style="text-align: justify">
                        [13] Yingqian Wang, Longguang Wang, et al., “Spatialangular interaction for light field image superresolution,” in ECCV, 2020.
                    </li>
                    <li style="text-align: justify">
                        [14] Yingqian Wang, Jungang Yang, et al., “Light field image super-resolution using deformable convolution,” IEEE TIP, vol. 30, pp. 1057–1071, 2020.
                    </li>
                    <li style="text-align: justify">
                        [20] Shuo Zhang, Song Chang, and Youfang Lin, “Endto-end light field spatial super-resolution network using multiple epipolar geometry,” IEEE TIP, vol. 30, pp. 5956–5968, 2021.
                    </li>
                    <li style="text-align: justify">
                        [21] Shunzhou Wang, Tianfei Zhou, Yao Lu, and Huijun Di, “Detail-preserving transformer for light field image super-resolution,” in AAAI, 2022.
                    </li>
                </ul>
            </div>
        </div>
        <hr />
        <!-------------------------CITATION---------------------------->
        <h2 id="cite" class="text-center text-md-start">
            <i class="fas fa-map-marker"></i>&nbsp;Citation (BibTeX)
        </h2>
        <div class="row">
            <div class="col" id="jumbo">
        <p id="myInput">
          <span style="display: block; padding-left: 35px">@misc{kar2022subaperture,><br />
            <span style="padding-left: 53px; display: block">title={Sub-Aperture Feature Adaptation in Single Image 
                Super-resolution Model for Light Field Imaging},<br />
              author={Aupendu Kar and Suresh Nehra and Jayanta Mukhopadhyay and
              Prabir Kumar Biswas},<br />
              booktitle={2022 IEEE International Conference on Image Processing (ICIP)},<br />
              year={2022},<br />
              organization={IEEE}<br /></span>
            }</span>
        </p>
            </div>
        </div>
        <hr />

        <!-----------------------------FOOTER------------------------------->
        <footer>
            <p style="text-align: center">
                <i class="far fa-copyright"></i> 2022
                <a href="https://github.com/aupendu" target="_blank">Aupendu Kar</a>.
                Made in
                <a href="https://www.incredibleindia.org/" target="_blank"><img id="flag"
                        src="/assets/images/india-flag-icon-32.png" alt="My Great Country India's Flag" /></a>
                by
                <a href="https://thingsbypatra.pythonanywhere.com//" target="_blank">Patra
                </a>
            </p>
        </footer>
    </div>

    <!--SCRIPTS (.js)-->
    <!--JQUERY-->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"
        integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ=="
        crossorigin="anonymous" referrerpolicy="no-referrer"></script>

    <!--Font Awesome 5-->
    <script src="https://kit.fontawesome.com/58bac38d13.js" crossorigin="anonymous"></script>

    <!--Bootstrap 5-->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>

    <!--External JS-->
    <script src="lfsafa-sr/subjs.js"></script>
</body>

</html>
